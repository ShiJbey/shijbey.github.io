<!doctype html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="description" content="Portfolio website for Shi Johnson-Bey, Ph.D. student in the Computational Media Dept. at UC Santa Cruz."/><meta name="image" content="/images/headshot.jpg"/><meta name="og:title" content="Shi Johnson-Bey | Projects"/><meta name="og:description" content="Portfolio website for Shi Johnson-Bey, Ph.D. student in the Computational Media Dept. at UC Santa Cruz."/><meta name="og:type" content="website"/><meta name="twitter:card" content="summary"/><meta name="twitter:creator" content="shijbey"/><meta name="twitter:title" content="Shi Johnson-Bey | Projects"/><meta name="twitter:description" content="Portfolio website for Shi Johnson-Bey, Ph.D. student in the Computational Media Dept. at UC Santa Cruz."/><meta name="twitter:image" content="/images/headshot.jpg"/><meta name="viewport" content="width=device-width,initial-scale=1"><title>Shi Johnson-Bey | Projects</title><script defer="defer" src="238.bundle.js"></script><script defer="defer" src="shared.bundle.js"></script></head><body><header><nav class="navbar navbar-expand-lg navbar-dark custom-nav"><div class="container container-fluid"><a href="/" class="navbar-brand"><img src="/favicon.ico" alt="Shi Johnson-Bey" width="30" height="30" class="d-inline-block align-text-top"> Shi Johnson-Bey </a><button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav me-auto mb-2 mb-lg-0"><li class="nav-item"><a class="nav-link" href="/">Home</a></li><li class="nav-item"><a class="nav-link active" aria-current="page" href="/projects.html">Projects</a></li><li class="nav-item"><a class="nav-link" href="/graphic-design.html">Graphic Design</a></li><li class="nav-item"><a class="nav-link" href="/cv.html">Resume</a></li></ul></div></div></nav></header><main><div class="container mt-5"><h1 class="text-center display-1 mb-3">Projects</h1><h2 class="d-block d-md-none text-center">Unity-TDRS</h2><div class="row mb-4"><div class="col col-12 col-md-6 project-image p-3"><img src="/images/projects/TDRS.jpg" alt="screenshot of Calypso sample game." class="w-100 rounded shadow"/></div><div class="col col-12 col-md-6 project-description"><div><h2 class="d-none d-md-block">TDRS</h2><p><img src="https://img.shields.io/badge/Status-Active-green?style=for-the-badge" alt=""/></p><p>TDRS (Trait-Driven Relationship System) is a toolkit for modeling dynamic character relationships for life sims, dating sims, visual novels, and adventure games in Unity. It enables game developers to track relationships between social entities (NPCs, players, factions, etc.), apply various traits that modify how characters feel about each other, and dispatch various social event that change relationships and build interpersonal histories. Game designers can leverage this package for NPC decision-making, customizing dialogue, and content gating. TDRS is currently used as the relationship system for Anansi.</p><div><a href="https://github.com/ShiJbey/TDRS" rel="none"><button class="btn btn-primary">View on GitHub</button></a></div></div></div></div><hr><h2 class="d-block d-md-none text-center">Anansi</h2><div class="row mb-4"><div class="col col-12 col-md-6 project-image p-3"><img src="https://github.com/ShiJbey/Calypso/assets/11076525/46455e67-94b6-49e5-a072-980bd9ca6754" alt="screenshot of Calypso sample game." class="w-100"/></div><div class="col col-12 col-md-6 project-description"><div><h2 class="d-none d-md-block">Anansi</h2><p><img src="https://img.shields.io/badge/Status-Active-green?style=for-the-badge" alt=""/></p><p>Anansi is a framework for creating social simulation-driven visual novel experiences in Unity. It combines the Ink narrative scripting language, a storylet architecture, and a social simulation that manages non-player character (NPC) schedules, emotions, personality traits, and relationships. Interactions with NPCs affect their feelings toward the player and other NPCs. Additionally, NPCs can reason about their relationship with the player and respond to events that happen to other characters in their social circle.</p><div><a href="https://github.com/ShiJbey/Anansi" rel="none"><button class="btn btn-primary">View on GitHub</button></a></div></div></div></div><hr><h2 class="d-block d-md-none text-center">Neighborly</h2><div class="row mb-4"><div class="col col-12 col-md-6 project-image p-3"><img src="/images/projects/cityviz_screenshot.png" alt="screenshot of isometric city builder" class="w-100 rounded shadow"/></div><div class="col col-12 col-md-6 project-description"><div><h2 class="d-none d-md-block">Neighborly</h2><p><img src="https://img.shields.io/badge/Status-Active-green?style=for-the-badge" alt=""/></p><p>Neighborly is a story-generation-focused agent-based modeling framework. It enables users to simulate the lives and histories of characters living within a single settlement. The fun of neighborly comes from exploring the generated history and seeing how the behaviors of the various agents led to intriguing and humorous emergent stories.</p><p>Neighborly combines game-inspired elements from Roguelike games, such as <a href="https://www.bay12games.com/dwarves/">Dwarf Fortress</a> and <a href="https://www.cavesofqud.com/">Caves of Qud</a>, with the authorability and data science focus od agent-based modeling frameworks like <a href="https://mesa.readthedocs.io/en/stable/">Mesa</a>.</p><div><a href="https://github.com/ShiJbey/neighborly" rel="none"><button class="btn btn-primary">View on GitHub</button></a></div></div></div></div><hr><h2 class="d-block d-md-none text-center">Jyackl.com</h2><div class="row mb-4"><div class="col col-12 col-md-6 project-image p-3"><img src="/images/projects/jyackl.jpg" alt="Screenshot of Jyackl.com" class="w-100 rounded shadow"/></div><div class="col col-12 col-md-6 project-description"><div><h2 class="d-none d-md-block">Jyackl.com</h2><p><img src="https://img.shields.io/badge/Status-Inactive-red?style=for-the-badge" alt=""/></p><p>Jyackl (pronounced like Jackal) was an online directory of Black-owned businesses in Washington DC, Maryland, and Virginia. This was the other side of my social media work as a part of <em>The Blacklist DMV</em>. We wanted to make a living artifact that cataloged all the Black-owned businesses as services in the DMV area. I did all the design and coding for the web app. You can still try it out.</p><div><a href="https://jyackl.com" rel="none"><button class="btn btn-primary">Go to Jyackl.com</button></a></div></div></div></div><hr><h2 class="d-block d-md-none text-center">Infiniforge</h2><div class="row mb-4"><div class="col col-12 col-md-6 project-image p-3"><img src="/images/projects/sword.gif" alt="spinning sword 3D model generated with Infiniforge." class="w-100 rounded shadow"/></div><div class="col col-12 col-md-6 project-description"><div><h2 class="d-none d-md-block">Infiniforge</h2><p><img src="https://img.shields.io/badge/Status-Inactive-red?style=for-the-badge" alt=""/></p><p>I started designing this project in 2016. At the time, I was heavily interested in both blacksmithing and procedural generation. I didn't know anything about computer graphics or PCG when I started. So, this project served as my introduction to both of those. Over the past three years, this project has helped me to grow more as a programmer. I continue to add to Infiniforge, even though it was to be submitted for the <a href="https://www.reddit.com/r/proceduralgeneration/comments/4wubjy/monthly_challenge_9_august_2016_procedural_weapons/" rel="none">August 2016 /procedural_generation subreddit challenge</a>. Infiniforge is a NodeJS module that generates and exports 3D meshes (using ThreeJs) as glTF JSON. You can import the models into Unity or other software that supports the format.</p><div class="mb-3"><a href="/infiniforge.html"><button class="btn btn-primary">Play the demo!</button></a></div><div class="mb-3"><a href="https://github.com/ShiJbey/Infiniforge" rel="none"><button class="btn btn-primary">View on GitHub</button></a></div></div></div></div><hr><h2 class="d-block d-md-none text-center">Centrifuge</h2><div class="row mb-4"><div class="col col-12 col-md-6 project-image p-3"><img src="/images/projects/editor_screenshot.png" alt="screenshot of custom editor" class="w-100 rounded shadow"/></div><div class="col col-12 col-md-6 project-description"><div><h2 class="d-none d-md-block">Centrifuge</h2><p><img src="https://img.shields.io/badge/Status-Inactive-red?style=for-the-badge" alt=""/></p><p>Node-based story-sifting tool for character-driven world simulations. This was my first project as a grad student at UCSC. I intended to build a graphical tool that helped people search for characters that met certain preconditions, such as experiencing a specific series of events, knowing a particular character, or any other interesting pattern. The other tools for story-sifting up to this point were all text-based domain-specific languages. Centrifuge is a cross-platform desktop app built with electron.</p><div><a href="https://github.com/ShiJbey/centrifuge" rel="none"><button class="btn btn-primary">View on GitHub</button></a></div></div></div></div><hr><h2 class="d-block d-md-none text-center">Magpie</h2><div class="row mb-4"><div class="col col-12 col-md-6 project-image p-3"><img src="/images/projects/magpie.jpg" alt="Magpie promotional art" class="w-100 rounded shadow"/></div><div class="col col-12 col-md-6 project-description"><div><h2 class="d-none d-md-block">Magpie</h2><p><img src="https://img.shields.io/badge/Status-Inactive-red?style=for-the-badge" alt=""/></p><p>This was the final project for my Fall 2018 15-466: Computer Game Programming course. I worked on a team with three other students where my primary role was to write the code which imported our 3D assets, built the level, and instanced characters/animations. In the game, you play a Magpie bird stealing items from a museum. How many things can you steal before you're caught by security?</p><div><a href="https://github.com/ShiJbey/Magpie" rel="none"><button class="btn btn-primary">View on GitHub</button></a></div></div></div></div><hr><h2 class="d-block d-md-none text-center">Teaching Machine Learning Agents to Box</h2><div class="row mb-4"><div class="col col-12 col-md-6 project-image p-3"><img src="/images/projects/ml-boxing.gif" alt="Animation of characters boxing in a ring" class="w-100 rounded shadow"/></div><div class="col col-12 col-md-6 project-description"><div><h2 class="d-none d-md-block">Teaching Machine Learning Agents to Box</h2><p><img src="https://img.shields.io/badge/Status-Inactive-red?style=for-the-badge" alt=""/></p><p>I threw this project together over the course of a week as an entry in Unity's first challenge for their new 'Ml-Agents' machine learning workflow. I had tossed around the idea of using machine learning to train AI agents in fighting games, but I had never gotten around to it until then. The agents learn via Reinforcement Learning and are given a simple policy that positively rewards landed punches on the opponent and negatively awards taking damage. Other behaviors, such as successful blocking and advancing on the opponent, are also rewarded.</p><div><a href="https://github.com/ShiJbey/Ml-Agent-Boxing" rel="none"><button class="btn btn-primary">View on GitHub</button></a></div></div></div></div><hr><h2 class="d-block d-md-none text-center">Auditory Brain-Computer Interfaces for VR</h2><div class="row mb-4"><div class="col col-12 col-md-6 project-image p-3"><img src="/images/projects/vr-screenshot.png" alt="Screenshot of VR experimentation environment" class="w-100 rounded shadow"/></div><div class="col col-12 col-md-6 project-description"><div><h2 class="d-none d-md-block">Auditory Brain-Computer Interfaces for VR</h2><p><img src="https://img.shields.io/badge/Status-Inactive-red?style=for-the-badge" alt=""/></p><p>This project was my master's research project. The goal was to explore the use of an auditory P300 BCI paradigm for enabling users to select objects in virtual reality. I ended with an EEG-hardware agnostic Unity project that could run different P300 paradigms in virtual reality. While running the unity scene, EEG data is streamed from the headset and written out to files to be processed. For example, one can take recorded EEG data using a machine learning classifier to predict what object the user wants to select. Pictured is the virtual apartment environment with three objects used during testing.</p><div><a href="/publications/Event_Related_Potentials_for_Virtual_Reality_Interactions.pdf"><button class="btn btn-danger mb-3">Download Masters thesis</button></a></div><div><a href="https://github.com/ShiJbey/AudioERP" rel="none"><button class="btn btn-primary">View on GitHub</button></a></div></div></div></div></div></main><footer><div class="container py-4 footer-content"><div class="row"><div class="col">&copy; Ishmael Johnson-Bey 2024</div></div></div></footer></body></html>